
import {
    f_add_css,
    f_s_css_prefixed,
    o_variables, 
    f_s_css_from_o_variables
} from "https://deno.land/x/f_add_css@1.1/mod.js"

import {
    f_o_html__and_make_renderable,
}
from 'https://deno.land/x/f_o_html_from_o_js@2.9/mod.js'

import {
    f_n_idx_binding_from_params,
    f_o_gpu_gateway, 
    f_o_gpu_gateway__from_simple_fragment_shader,
    f_o_gpu_gateway_webgpu,
    f_o_gpu_gateway_webgpu_dataitem__buffer_from_v_as_type,
    f_o_gpu_texture__from_o_web_api_object,
    f_render_o_gpu_gateway,
    f_render_o_gpu_gateway_webgpu,
    f_s_autogenerated_accessor_functions,
    f_s_binding_declaration__from_o_gpu_gateway_webgpu,
    f_update_data_in_o_gpu_gateway,
    f_update_data_in_o_gpu_gateway_webgpu,
}
from 'https://deno.land/x/gpugateway@0.5/mod.js'

import { 
    O_beat,
    O_note,
    O_pattern,
    O_sample
 } from "./classes.module.js";

 
o_variables.n_rem_font_size_base = 1. // adjust font size, other variables can also be adapted before adding the css to the dom
o_variables.n_rem_padding_interactive_elements = 0.5; // adjust padding for interactive elements 
f_add_css(
    `
    canvas{
        width: 100%;
        height: 100%;
        position:fixed;
        z-index:-1;
    }
    ${
        f_s_css_from_o_variables(
            o_variables
        )
    }
    `

);

let o_gpu_gateway = null;
const o_audio_ctx = new (window.AudioContext || window.webkitAudioContext)();
// Create a gain node (or other nodes you might need)
const o_gain_node = o_audio_ctx.createGain();
o_gain_node.connect(o_audio_ctx.destination);


let f_v_audio_buffer = async function(s_url) {
    const o_resp = await fetch(s_url);
    const a_n_u8 = await o_resp.arrayBuffer();
    const audioBuffer = await o_audio_ctx.decodeAudioData(a_n_u8);
    return audioBuffer;
}

// Function to play the audio buffer
let f_play_audio_buffer = function(v_audio_buffer) {
    const source = o_audio_ctx.createBufferSource();
    source.buffer = v_audio_buffer;
    source.connect(o_gain_node); // Connect to the gain node
    source.start(0);
}

let f_update_a_o_sample = async function(){
    for(let o_sample of o_state.o_beat.a_o_sample){
        o_sample.v_audio_buffer = await f_v_audio_buffer(o_sample.s_url_audio); 
    }
}

let o_state = {
    o_beat: new O_beat(
        'default', 
        80, 
        false, 
        [
            new O_sample(
                'hihat', 
                './hihat.png', 
                0, 
                1.,
                './Samples/hihat-acoustic01.wav', 
                8, 
                0,
                [
                    new O_pattern(
                        1,
                        [
                            new O_note( (1./8.)*0., (1./8.), 1.0, 1.0), 
                            new O_note( (1./8.)*1., (1./8.), 1.0, 1.0), 
                            new O_note( (1./8.)*2., (1./8.), 1.0, 1.0), 
                            new O_note( (1./8.)*3., (1./8.), 1.0, 1.0), 
                            new O_note( (1./8.)*4., (1./8.), 1.0, 1.0), 
                            new O_note( (1./8.)*5., (1./8.), 1.0, 1.0), 
                            new O_note( (1./8.)*6., (1./8.), 1.0, 1.0), 
                            new O_note( (1./8.)*7., (1./8.), 1.0, 1.0),
                        ]
                    )
                ]
            ),
            new O_sample(
                'kick', 
                './kick.png', 
                0, 
                1.,
                './Samples/kick-classic.wav', 
                8, 
                0,
                [
                    new O_pattern(
                        4,
                        [
                            new O_note( (1./4.)*0., (1./8.), 1.0, 1.0), 
                            new O_note( (1./4.)*3., (1./8.), 1.0, 1.0), 
                        ]
                    )
                ]
            ),
            new O_sample(
                'snare', 
                './snare.png', 
                0, 
                1.,
                './Samples/snare-acoustic01.wav', 
                8, 
                0,
                [
                    new O_pattern(
                        2,
                        [
                            new O_note( (1./4.)*2., (1./8.), 1.0, 1.0), 
                            new O_note( (1./4.)*4., (1./8.), 1.0, 1.0), 
                        ]
                    )
                ]
            )
        ]
    ),
    s_msg: '', 
    a_o_msg: [], 
    o_trn_nor_mouse_last: [.5,.5],
    o_trn_nor_mouse: [.5,.5], 
    o_trn_nor_mouse_follow: [0.,0.]
}
window.o_state = o_state

await f_update_a_o_sample();

window.f_play_audio_buffer = f_play_audio_buffer
window.addEventListener('pointermove', (o_e)=>{
    if(o_gpu_gateway){
        o_state.o_trn_nor_mouse = [
            (o_e.clientX / window.innerWidth), 
            1.-(o_e.clientY / window.innerHeight), 
        ];
    
        f_update_data_in_o_gpu_gateway(
            {
                o_trn_nor_mouse: o_state.o_trn_nor_mouse_last,
                o_trn_nor_mouse_last: o_state.o_trn_nor_mouse, 
            }, 
            o_gpu_gateway, 
        )
        o_state.o_trn_nor_mouse_last = o_state.o_trn_nor_mouse
    }
})

// //readme.md:start
document.body.appendChild(
    await f_o_html__and_make_renderable(
        {
            s_tag: 'div', 
            class: "app",
            a_o: [
                Object.assign(
                    o_state, 
                    {
                        o_js__o_beat: {
                            f_o_jsh: ()=>{
                                return {
                                    class: "o_beat",
                                    a_o: [
                                        {
                                            s_tag: "button", 
                                            innerText: (o_state.o_beat.b_playing) ? "stop" : "play", 
                                            onpointerdown: async ()=>{
                                                o_state.o_beat.b_playing = !o_state.o_beat.b_playing;
                                                await o_state.o_js__o_beat._f_render();
                                            }
                                        },
                                        {
                                            s_tag: "input", 
                                            type: "number", 
                                            min: 1, 
                                            max: 300,
                                            value: o_state.o_beat.n_bpm,
                                            oninput: (o_e)=>{
                                                o_state.o_beat.n_bpm = parseFloat(o_e.target.value);
                                            }
                                        } ,
                                        {
                                            innerText: `BPM`
                                        },
                                    ]
                                }
                            }
                        }
                    }
                ).o_js__o_beat,
                {
                    class: "bottom", 
                    a_o: [
                        Object.assign(
                            o_state, 
                            {
                                o_js__a_o_sample: {
                                    f_o_jsh: ()=>{
                                        return {
                                            class: "a_o_sample",
                                            a_o: o_state.o_beat.a_o_sample.map(o_sample=>{

                                                return {
                                                    a_o: [
                                                        {
                                                            innerText: o_sample.s_name
                                                        }, 
                                                        // icon todo 
                                                        // sample from yt video todo
                                                        // sample from microphone todo
                                                    ]
                                                }
                                            })
                                        }
                                    }
                                }
                            }
                        ).o_js__a_o_sample,
                        {
                            id: "canvas_parent"
                        }
                    ]
                }
            ]
        }
    )
);

let o_canvas = document.createElement('canvas');
o_canvas.width = window.innerWidth
o_canvas.height = window.innerHeight
document.querySelector("#canvas_parent").appendChild(o_canvas);


// we are going to missuse a texture to pass multidimensional data to the shader, 
// each row of the texture is dedicated to a o_sample
// each 

let n_len_a_o_sample_max = 120;
let n_len_a_o_note_max = 1024;





let n_len_a_o_trn = 50;
let n_idx_a_o_trn = 0;
o_gpu_gateway = f_o_gpu_gateway(
    o_canvas, 
    `#version 300 es
    in vec4 a_o_vec_position_vertex;
    out vec2 o_trn_nor_pixel;
    void main() {
        gl_Position = a_o_vec_position_vertex;
        o_trn_nor_pixel = (a_o_vec_position_vertex.xy) / 2.0; // Convert from clip space to texture coordinates
    }`,
    `#version 300 es
    precision mediump float;
    in vec2 o_trn_nor_pixel;
    out vec4 fragColor;
    uniform float n_ms_time;
    uniform vec2 o_trn_nor_mouse;
    uniform vec2 o_trn_nor_mouse_last;
    uniform vec2 o_trn_nor_mouse_follow;
    uniform vec2 o_scl_canvas;
    uniform vec4 a_o_col[${n_len_a_o_trn}];
    uniform float n_len_a_o_col;
    uniform float n_len_a_o_sample;
    uniform float n_len_a_o_sample_max;
    uniform float n_len_a_o_note_max; 
    uniform float a_n_len_a_o_note[${n_len_a_o_sample_max}];
    uniform sampler2D o_texture;

    float f_n_square(
        vec2 o_trn_pix,
        vec2 o_trn, 
        vec2 o_scl
    ){
        o_trn_pix.y = 1.-o_trn_pix.y;
        vec2 o_diff = o_trn_pix-o_trn-o_scl;
        o_diff*=2.;    
        o_diff+=o_scl;
    
        o_diff*=1./(o_scl);
        float n = max(abs(o_diff.x), abs(o_diff.y));
        return 1.-n; 
    }
    void main() {

        vec2 o_trn_nor_pixel_from_zero = o_trn_nor_pixel+vec2(0.5);
        float n_idx_a_o_col = abs(o_trn_nor_pixel_from_zero.y*n_len_a_o_col);
        fragColor = a_o_col[int(n_idx_a_o_col)];
        // fragColor = vec4(o_trn_nor_pixel_from_zero.y);
        
        // float n_idx_a_o_sample = abs(o_trn_nor_pixel_from_zero.y*n_len_a_o_sample);

        float n_min = 1.;

        for(float n_idx_a_o_sample = 0.; n_idx_a_o_sample < n_len_a_o_sample; n_idx_a_o_sample+=1.){

            float n_len_a_o_note = a_n_len_a_o_note[int(n_idx_a_o_sample)];
            float n_idx_a_o_note = 0.;
            for(float n_idx_a_o_note = 0.; n_idx_a_o_note < n_len_a_o_note; n_idx_a_o_note+=1.){
    
                vec4 o_note = texture(o_texture, 
                    vec2(
                        n_idx_a_o_note/n_len_a_o_note_max,
                        n_len_a_o_sample/n_idx_a_o_sample
                    )
                );
    
                float n_nor_start = o_note[0];
                float n_nor_duration = o_note[1];
                float n_nor_velocity = o_note[2];
                float n_nor_pitch = o_note[3];

                vec2 o_trn = vec2(
                    0.0,//n_nor_start,
                    n_idx_a_o_sample / 10.
                );
                vec2 o_scl = vec2(
                    0.2, //n_nor_duration, 
                    0.2 //1./n_len_a_o_sample
                );
                float n = f_n_square(
                    o_trn_nor_pixel_from_zero, 
                    o_trn, 
                    o_scl
                );
                // n = length(o_trn_nor_pixel_from_zero-o_trn)*20.;
                // n = sin(n*33.);
                if(n < n_min){
                    n_min = n;
                }
            }
        }


        // float n_idx = abs(o_trn_nor_pixel_from_zero.y*n_len_a_o_sample);
        // fragColor = vec4(a_n_len_a_o_note[int(n_idx)]);
    
        // vec4 o_test = texture(o_texture, 
        //     vec2(
        //         0.001,
        //         0.0
        //     )
        // );
        // float n = length(
        //     o_trn_nor_pixel_from_zero.xy - o_test.xy
        // )*20.;
        fragColor = vec4(n_min);
    }
    `,
)


var a_o_col = new Float32Array(
    [
        0.2, 0.3, 0.3, 1.0,
        0.8, 0.3, 0.8, 1.0,
    ]
);
let o_gl = o_gpu_gateway.o_ctx;

var buffer = o_gl.createBuffer();
o_gl.bindBuffer(o_gl.ARRAY_BUFFER, buffer);
o_gl.bufferData(o_gl.ARRAY_BUFFER, a_o_col, o_gl.STATIC_DRAW);
var o_location_a_o_col = o_gl.getUniformLocation(o_gpu_gateway.o_shader__program, 'a_o_col');
o_gl.uniform4fv(o_location_a_o_col, a_o_col);

let a_n_len_a_o_note = new Float32Array(new Array(n_len_a_o_sample_max).fill(0).map(()=>{return Math.random()}))

const o_location_a_n_len_a_o_note = o_gl.getUniformLocation(o_gpu_gateway.o_shader__program, 'a_n_len_a_o_note');

// Create and bind the texture
const o_texture = o_gl.createTexture();
o_gl.bindTexture(o_gl.TEXTURE_2D, o_texture);


// Set the texture parameters
o_gl.texParameteri(o_gl.TEXTURE_2D, o_gl.TEXTURE_WRAP_S, o_gl.CLAMP_TO_EDGE);
o_gl.texParameteri(o_gl.TEXTURE_2D, o_gl.TEXTURE_WRAP_T, o_gl.CLAMP_TO_EDGE);
o_gl.texParameteri(o_gl.TEXTURE_2D, o_gl.TEXTURE_MIN_FILTER, o_gl.NEAREST);
o_gl.texParameteri(o_gl.TEXTURE_2D, o_gl.TEXTURE_MAG_FILTER, o_gl.NEAREST);

// Initialize the texture with a Uint8Array
const n_scl_x = n_len_a_o_note_max;
const n_scl_y = n_len_a_o_sample_max;
const a_n_u8_texture = new Uint8Array(n_scl_x * n_scl_y * 4); // RGBA format
for (let n_i = 0; n_i < a_n_u8_texture.length; n_i++) {
    a_n_u8_texture[n_i] = 0; // Example data
}
o_gl.texImage2D(o_gl.TEXTURE_2D, 0, o_gl.RGBA, n_scl_x, n_scl_y, 0, o_gl.RGBA, o_gl.UNSIGNED_BYTE, a_n_u8_texture);

const o_location_texture = o_gl.getUniformLocation(o_gpu_gateway.o_shader__program, 'o_texture');
o_gl.uniform1i(o_location_texture, 0);


// Bind the texture to texture unit 0
o_gl.activeTexture(o_gl.TEXTURE0);
o_gl.bindTexture(o_gl.TEXTURE_2D, o_texture);

o_gl.uniform1fv(o_location_a_n_len_a_o_note, a_n_len_a_o_note);


let f_update_a_n_u8_texture = function(a_n_u8){
    if (a_n_u8.length !== n_scl_x * n_scl_y * 4) {
        console.error('The new data array must have the same length as the initial data array.');
        return;
    }

    o_gl.bindTexture(o_gl.TEXTURE_2D, o_texture);
    o_gl.texImage2D(o_gl.TEXTURE_2D, 0, o_gl.RGBA, n_scl_x, n_scl_y, 0, o_gl.RGBA, o_gl.UNSIGNED_BYTE, a_n_u8);
}

let f_resize = ()=>{
    o_canvas.width = window.innerWidth
    o_canvas.height = window.innerHeight
    f_update_data_in_o_gpu_gateway(
        {o_scl_canvas: [
            o_canvas.width,
            o_canvas.height
        ]}, 
        o_gpu_gateway, 
    )
}
window.addEventListener('resize',()=>{
    f_resize()
});
f_resize()

let f_update_from_o_beat = function(o_beat){
    for(let n_idx_a_o_sample in o_beat.a_o_sample){
        n_idx_a_o_sample = parseInt(n_idx_a_o_sample)
        let o_sample = o_beat.a_o_sample[n_idx_a_o_sample];
        let o_pattern = o_sample.a_o_pattern[o_sample.n_idx_a_o_pattern];
        a_n_len_a_o_note[n_idx_a_o_sample] = o_pattern.a_o_note.length;
        for(let n_idx_a_o_note in o_pattern.a_o_note){
            n_idx_a_o_note = parseInt(n_idx_a_o_note)
            let o_note = o_pattern.a_o_note[n_idx_a_o_note];
            let n_trn_y = n_idx_a_o_sample;
            let n_trn_x = n_idx_a_o_note;
            // debugger
            // console.log(
            //     n_trn_y*n_scl_x*4+n_trn_x+1, 
            //     o_note.n_nor_duration
            // )
            a_n_u8_texture[n_trn_y*n_scl_x*4+n_trn_x+0] = (o_note.n_nor_start)*255;
            a_n_u8_texture[n_trn_y*n_scl_x*4+n_trn_x+1] = (o_note.n_nor_duration)*255;
            a_n_u8_texture[n_trn_y*n_scl_x*4+n_trn_x+2] = (o_note.n_nor_velocity)*255;
            a_n_u8_texture[n_trn_y*n_scl_x*4+n_trn_x+3] = (o_note.n_nor_pitch)*255;
            // console.log(a_n_u8_texture)
        }
    }

    f_update_a_n_u8_texture(a_n_u8_texture)
}

f_update_from_o_beat(o_state.o_beat);


let n_ms_wpn = 0;
let n_id_raf = 0;
let f_raf = function(){

    n_id_raf = window.requestAnimationFrame(f_raf);


    let a_n_len_a_o_note = new Float32Array(new Array(n_len_a_o_sample_max).fill(0).map(()=>{return Math.random()}))

    if(o_gpu_gateway){

        o_gpu_gateway.o_ctx.uniform1fv(o_location_a_n_len_a_o_note, a_n_len_a_o_note);
    
        console.log("asdf")
    
        let o_dir = [
            o_state.o_trn_nor_mouse[0] - o_state.o_trn_nor_mouse_follow[0],
            o_state.o_trn_nor_mouse[1] - o_state.o_trn_nor_mouse_follow[1],
        ];
        let n_t = 0.2;
        o_state.o_trn_nor_mouse_follow = [
            o_state.o_trn_nor_mouse_follow[0] + n_t*o_dir[0],
            o_state.o_trn_nor_mouse_follow[1] + n_t*o_dir[1],
        ]
        f_update_data_in_o_gpu_gateway(
            {
                o_trn_nor_mouse_follow: o_state.o_trn_nor_mouse_follow
            }, 
            o_gpu_gateway, 
        )
        
    
        // o_gpu_gateway.o_ctx.uniform4fv(o_location_a_o_col, a_o_col); // update
        let n_len_a_o_sample = o_state.o_beat.a_o_sample.length;
        console.log({n_len_a_o_sample})
        f_update_data_in_o_gpu_gateway(
            {
                n_len_a_o_col: a_o_col.length/4,
                n_ms_time: window.performance.now(), 
                n_len_a_o_sample_max, 
                n_len_a_o_sample, 
                n_len_a_o_note_max
            }, 
            o_gpu_gateway, 
        )
        f_render_o_gpu_gateway(
            o_gpu_gateway, 
        );
    }
}
n_id_raf = window.requestAnimationFrame(f_raf);


// //readme.md:end